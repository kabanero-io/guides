---
permalink: /guides/app-monitoring-ocp4.2/
---
:projectid: ocp-app-monitoring
:page-layout: guide-multipane
:page-duration: 60 minutes
:page-releasedate: 2020-02-02
:page-guide-category: basic
:page-description: Learn how to monitor applications on RHOCP 4.2 with Prometheus and Grafana.
:page-tags: ['monitoring', 'prometheus', 'grafana']
= Application Monitoring on Red Hat OpenShift Container Platform (RHOCP) 4.3 with Prometheus and Grafana

== Introduction

__The following guide has been tested with RHOCP 4.2/Kabanero 0.3.0 and RHOCP 4.3/Kabanero 0.6.0.__


For application monitoring on RHOCP, you need to set up your own Prometheus and Grafana deployments. Both Prometheus and Grafana can be set up via Operator Lifecycle Manager (OLM). 

=== Deploy an Application with MP Metrics Endpoint
Prior to deploying Prometheus, ensure that there is a running application that has a service endpoint for outputting metrics in Prometheus format. 

It is assumed such a running application has been deployed to the RHOCP cluster inside a project/namespace called `myapp`, and that the Prometheus metrics endpoint is exposed on path `/metrics`.

== Deploy Prometheus - Prometheus Operator

service_monitor.yaml
[source, yaml, linenums, role='code-column']
----
include::code/service_monitor.yaml[]
----

service_account.yaml
[source, yaml, linenums, role='code-column']
----
include::code/service_account.yaml[]
----

prometheus.yaml
[source, yaml, linenums, role='code-column']
----
include::code/prometheus.yaml[]
----


The Prometheus Operator is an open-source project originating from CoreOS and exists as a part of their Kubernetes Operator framework. The Kubernetes Operator framework is the preferred way to deploy Prometheus on a Kubernetes system. When the Prometheus Operator is installed on the Kubernetes system, you no longer need to hand-configure the Prometheus configuration. Instead, you create CoreOS ServiceMonitor resources for each of the service endpoints that needs to be monitored: this makes daily maintenance of the Prometheus server a lot easier. An architecture overview of the Prometheus Operator is shown below:

image::/img/guide/prometheusOperator.png[link="/img/guide/prometheusOperator.png" alt="Prometheus Operator"]

Using Operator Lifecycle Manager (OLM), Prometheus operator can be easily installed and configured in RHOCP Web Console.

=== Install Prometheus Operator Using Operator Lifecycle Manager (OLM)

The following procedure is based on https://medium.com/faun/using-the-operator-lifecycle-manager-to-deploy-prometheus-on-openshift-cd2f3abb3511[Using the Operator Lifecycle Manager to deploy Prometheus on OpenShift], with the added inclusion of OpenShift commands needed to complete each step.

. Create a new namespace for our Prometheus Operator deployment
+
[role="command"]
----
oc new-project prometheus-operator
----
+
. Go to OpenShift Container Platform web console and Click on Operators > OperatorHub. Using the OLM, Operators can be easily pulled, installed and subscribed on the cluster. Ensure that the Project is set to prometheus-operator. Search for Prometheus Operator and install it. Choose prometheus-operator under __A specific namespace on the cluster__ and subscribe.

. Click on Overview and create a service monitor instance. A ServiceMonitor defines a service endpoint that needs to be monitored by the Prometheus instance.

. Inside the Service Monitor YAML file, make sure *metadata.namespace* is your monitoring namespace. In this case, it will be prometheus-operator. *spec.namespaceSelector* and *spec.selector* for labels should be configured to match your app deployment's namespace and label. For example, inside [hotspot file=0]`service_monitor.yaml` file, an application with label *app: example-app* from namespace **myapp** will be monitored by the service monitor. If the metrics endpoint is secured, you can define a secured endpoint with authentication configuration by following the https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint[endpoint] API documentation of Prometheus Operator.
+
[role="code_command hotspot file=0", subs="quotes"]
----
Refer to the `service_monitor.yaml` file
----
+

. Create a Service Account with Cluster role and Cluster role binding to ensure you have the permission to get nodes and pods in other namespaces at the cluster scope. Refer to [hotspot file=1]`service_account.yaml`. Create the YAML file and apply it.
+
[role=command]
----
oc apply -f service_account.yaml
----
+

. Click on Overview and create a Prometheus instance. A Prometheus resource can scrape the targets defined in the ServiceMonitor resource.

. Inside the Prometheus YAML file, make sure *metadata.namespace* is prometheus-operator. Ensure *spec.serviceAccountName* is the Service Account's name that you have applied in the previous step. You can set the match expression to select which Service Monitors you are interested in under *spec.serviceMonitorSelector.matchExpressions* as in [hotspot file=2]`prometheus.yaml` file.
+
[role="code_command hotspot file=2", subs="quotes"]
----
Refer to the `prometheus.yaml` file
----
+
. Verify that the Prometheus services have successfully started. 
+
[source,role="no_copy"]
----
[root@rhel7-ocp]# oc get svc -n prometheus-operator
NAME                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
prometheus-operated   ClusterIP   None             <none>        9090/TCP         19h
----
+
. Check the server logs from one of the target pods to see if the services are running properly.
+
[source,role="no_copy"]
----
[root@rhel7-ocp]# oc get pods -n prometheus-operator
NAME                                   READY     STATUS    RESTARTS   AGE
prometheus-operator-7fccbd7c74-48m6v   1/1       Running   0          19h
prometheus-prometheus-0                3/3       Running   1          19h
prometheus-prometheus-1                3/3       Running   1          19h
[root@rhel7-ocp]# oc logs prometheus-prometheus-0 -c prometheus -n prometheus-operator
----
+

. Expose the prometheus-operated service to use the Prometheus console externally.
+
[source,role="no_copy"]
----
[root@rhel7-ocp]# oc expose svc/prometheus-operated -n prometheus-operator
route.route.openshift.io/prometheus-operated exposed
[root@rhel7-ocp]# oc get route -n prometheus-operator
NAME         HOST/PORT                                                 PATH      SERVICES     PORT      TERMINATION   WILDCARD
prometheus   prometheus-prometheus-operator.apps.9.37.135.153.nip.io             prometheus   web                     None
----
+
. Visit the Prometheus route and go to the Prometheus targets page. 
Check to see that the Prometheus targets page is picking up the target endpoints.

image::/img/guide/prometheus_endpoints.png[link="/img/guide/prometheus_endpoints.png" alt="Prometheus Target Page"]


== Deploy Grafana

grafana_datasource.yaml
[source, yaml, linenums, role='code-column']
----
include::code/grafana_datasource.yaml[]
----

grafana.yaml
[source, yaml, linenums, role='code-column']
----
include::code/grafana.yaml[]
----

grafana_dashboard.yaml
[source, yaml, linenums, role='code-column']
----
include::code/grafana_dashboard.yaml[]
----

Use Grafana dashboards to visualize the metrics. Perform the following steps to deploy Grafana and ensure that Prometheus endpoints are reachable as a data source in Grafana.

. Choose the *same namespace* as Prometheus Operator deployment.
+
[role="command"]
----
oc project prometheus-operator
----
+
. Go to OpenShift Container Platform web console and click Operators > OperatorHub. Search for Grafana Operator and install it. For __A specific namespace on the cluster__, choose prometheus-operator, and subscribe.

. Click Overview and create a Grafana Data Source instance.

. In the Grafana Data Source YAML file, make sure *metadata.namespace* is prometheus-operator. Set *spec.datasources.url* to the URL of the target datasource. For example, inside [hotspot file=0]`grafana_datasource.yaml` file, the Prometheus service is *prometheus-operated* on port *9090*, so the URL is set to __'http://prometheus-operated:9090'__.
+
[role="code_command hotspot file=0", subs="quotes"]
----
Refer to the `grafana_datasource.yaml` file
----
+

. Click Overview and create a Grafana instance.

. In the Grafana YAML file, make sure *metadata.namespace* is prometheus-operator. You can define the match expression to select which Dashboards you are interested in under *spec.dashboardLabelSelector.matchExpressions*. For example, inside [hotspot file=1]`grafana.yaml` file, the Grafana will discover dashboards with app labels having a value of *grafana*.
+
[role="code_command hotspot file=1", subs="quotes"]
----
Refer to the `grafana.yaml` file
----
+

. Click Overview and create a Grafana Dashboard instance.

. Copy [hotspot file=2]`grafana_dashboard.yaml` to Grafana Dashboard YAML file to check the Data Source is connected and Prometheus endpoints are discoverable.

+
[role="code_command hotspot file=2", subs="quotes"]
----
Apply `grafana_dashboard.yaml` file to check
----
+

. Click on Networking > Routes and go to Grafana's location to see the template dashboard. You can now consume all the application metrics gathered by Prometheus on the Grafana dashboard.

image::/img/guide/template_grafana_dashboard.png[link="/img/guide/template_grafana_dashboard.png" alt="Template Dashboard"]

[start=10]

. When importing your own Grafana dashboard, your dashboard should be configured under *spec.json* in Grafana Dashboard YAML file. Make sure under *"__inputs"*, the name matches with your Grafana Data Source's *spec.datasources*. For example, inside [hotspot file=2]`grafana_dashboard.yaml` file, *name* is set to "Prometheus".


== Configure Prometheus Operator to Detect Service Monitors in Other Namespaces

By default, the Prometheus Operator only watches the namespace it currently resides in, so in order to get the Prometheus Operator to detect Service Monitors created in other namespaces, you must apply the following configuration changes.

Depending on whether you have installed the Prometheus Operator from OLM or if you are using the Prometheus Operator deployment from Common Services, see the following sections to configure the Prometheus Operator to detect Service Monitors outside of the monitoring namespace.

=== Using the Prometheus Operator Installed from OLM

. In your monitoring namespace - in this case, the monitoring namespace is `prometheus-operator` - edit the OperatorGroup to add your application's namespace `myapp` to the list of targeted namesaces to be watched. This will change the *olm.targetNamespaces* variable that the Prometheus Operator uses for detecting namespaces to include your `myapp` namespace.
+
[role="command"]
----
oc edit operatorgroup
----
+

+
[source,role="no_copy"]
----
spec:
  targetNamespaces:
  - prometheus-operator
  - myapp
----
+

. Since we have changed the `prometheus-operator` namespace's OperatorGroup to monitor more than one namespace, the operators in this namespace must have the *MultiNamespace* installMode set to *true*. Prometheus Operator installed via OLM has the *MultiNamespace* installMode set to *false* by default, disabling monitoring more than one namespace, so this must be changed to *true*.
+
[role="command"]
----
oc edit csv prometheusoperator.0.32.0
----
+

+
[source,role="no_copy"]
----
spec:
  installModes:
  - supported: true
    type: OwnNamespace
  - supported: true
    type: SingleNamespace
  - supported: true
    type: MultiNamespace
  - supported: false
    type: AllNamespaces
----
+

. The same goes for the Grafana Operator, the *MultiNamespace* installMode set to *true*; edit the operator using:
+
[role="command"]
----
oc edit csv grafana-operator.v2.0.0 
----
+

. Edit the Prometheus instance to add the *serviceMonitorNamespaceSelector* definition. The empty brackets *{}* allow Prometheus to scrape from *all* namespaces:
+
[role="command"]
----
oc edit prometheus
----
+

+
[source,role="no_copy"]
----
spec:
  serviceMonitorNamespaceSelector: {}
----
+

Restart the Prometheus Operator and Grafana Operator pods to see the changes.

=== Using the Prometheus Operator Deployment from Common Services

. In the `kube-system` namespace, edit the existing `monitoring-prometheus-operator` deployment to add your application's namespace `myapp` to the list of namespaces to be watched:

+
[role="command"]
----
oc edit deployment monitoring-prometheus-operator
----
+

+
[source,role="no_copy"]
----
spec:
  ...
  template:
    ...
    spec:
      ...
      containers:
        ...
        args: 
        - '--namespaces=kube-system, myapp'
----
+

. Edit the Prometheus instance to add the *serviceMonitorNamespaceSelector* definition. The empty brackets *{}* allow Prometheus to scrape from *all* namespaces:

+
[role="command"]
----
oc edit prometheus
----
+

+
[source,role="no_copy"]
----
spec:
  serviceMonitorNamespaceSelector: {}
----
+
